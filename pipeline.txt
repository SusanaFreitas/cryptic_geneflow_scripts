## RAD analyses ##


useful paths:
reference genomes > ftp://ftpmrr.unil.ch/AsexGenomeEvol/timema/

1) Remove reads that failed Casava files
	script: removereads.sh

2) Read quality
	script: fastqc.sh

3) Check that the barcode and the RAD cutsite are intact, and demultiplexing of the data.
	script: process_stacks.sh

4) cloneFilter to remove PCR duplicates # I won't need this, since there wasn't a step to mark the PCR duplicates.
	skip this step

5) Alignment : BWA better than bowtie (that leaves mores reads out, but test which is best)
	script: 05-mapreads.sh


	helpful oneliners:
	- repeat the same line 88 times in a file
while read line; do for i in {1..88}; do echo "$line"; done; done < inds.end > file


6) SAMTOOLS: sort, filter only aligned reads and index samples (read groups are added during the bwa alignment)
	script: 06-sortfilter.sh

7.1 ) STACKS

filter MAPQ > 30

Call SNPs

# during the analyses Darren (and then I confirmed it in my data) found a problem of adapter contamination.
# This caused that the bwa-mem called several softed-clipping reads (alignments) that belonged to the adapter.
# However, when observing the bam files I found that the reads with the softclipped alignments would map
# into the wrong places, giving a SNP whereas reads without adapters wouldn't present that SNP.



7.2 ) freebayes
- Freebayes does not call only SNPS. The vcf will have to be filtered:
	- keep Only SNPs (break MNPs - multi nucleotide polymorphisms- into SNPs)

$ vcflib vcfallelicprimitives -kg Tge.fb.vcf > Tge.fb.filtmult.vcf
/usr/lib/vcflib/bin/vcfallelicprimitives -kg Tms.fb.vcf > Tge.alprim.vcf
/usr/lib/vcflib/bin/vcfallelicprimitives -kg Tms.trim2.fb.vcf > Tge.trim2.alprim.vcf
/usr/lib/vcflib/bin/vcfallelicprimitives -kg Tms.trim3.fb.vcf > Tge.trim3.alprim.vcf

usage: /usr/lib/vcflib/bin/vcfallelicprimitives [options] [file]

options:
    -m, --use-mnps          Retain MNPs as separate events (default: false).
    -t, --tag-parsed FLAG   Tag records which are split apart of a complex allele with this flag.
    -L, --max-length LEN    Do not manipulate records in which either the ALT or
                            REF is longer than LEN (default: 200).
    -k, --keep-info         Maintain site and allele-level annotations when decomposing.
                            Note that in many cases, such as multisample VCFs, these won't
                            be valid post-decomposition.  For biallelic loci in single-sample
                            VCFs, they should be usable with caution.
    -g, --keep-geno         Maintain genotype-level annotations when decomposing.  Similar
                            caution should be used for this as for --keep-info.

If multiple allelic primitives (gaps or mismatches) are specified in
a single VCF record, split the record into multiple lines, but drop all
INFO fields (unless you choose the -kg options).  Does not handle genotypes (yet).  MNPs are split into
multiple SNPs unless the -m flag is provided.  Records generated by splits have th

--use-best-n-alleles all (default) --min-mapping-quality 30 --min-coverage 5
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.fb_DPfilter.vcf > Tms.fb_posvcflib.vcf
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.trim2.fb_DPfilter.vcf > Tms.trim2.fb_posvcflib.vcf
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.trim3.fb_DPfilter.vcf > Tge.trim3.fb_posvcflib.vcf



######################################################################
###### OBSERVE THE NUMBER OF READS PER POSITION IN THE fb vcfs #######
######################################################################
### To decide how to filter the positions, I will plot the read distribution
# per variant and decide the cutoff according to the 10 and 99 quantiles.

#### gatk ####
GenomeAnalysisTK VariantsToTable \
 -R 3_Tms_b3v08.fasta \
 -V Tms.trim2.fb.vcf \
 -F CHROM -F POS -GF GT -GF DP \
 --output Tms.trim2.fb.DP.table

#### BASH ####
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.trim2.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.trim3.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done

#### R ####
# define the file names list (10 samples here) 
nameList <- c()
for (i in 3:96) { # 21 - odd number for 10 samples 
  if (i %% 2 ==1) nameList <- append(nameList, paste(i, ".DP", sep=""))
}

qlist <- matrix(nrow = 47, ncol = 3) # define number of samples (10 samples here)
qlist <- data.frame(qlist, row.names=nameList)
colnames(qlist)<-c('5%', '10%', '99%')

#jpeg("Tms.fb.DP.jpeg", height=1600, width=1200)
pdf("Tms.trim3.fb.DP.pdf", height=20, width=15)
par(mar=c(1, 1, 1, 1), cex=1.5, mfrow=c(24,4)) # define number of plots for your sample
for (i in 1:32) {
  DP <- read.table(nameList[i], header = T)
  qlist[i,] <- quantile(DP[,1], c(.05, .1, .99), na.rm=T)
  d <- density(DP[,1], from=0, to=100, bw=1, na.rm =T)
  plot(d, xlim = c(0,100), main=nameList[i], col="blue", xlab = dim(DP)[1], lwd=2)
  abline(v=qlist[i,c(1,3)], col='red', lwd=3)
}
dev.off()

write.table(qlist, "GVCFall.DP.percentiles.txt")


######################################################################
############## Filter by DP - "DP < 8 || DP > 200" ###################
######################################################################

##### - keep reads DP > 8 and DP < 200
#### gatk ####
GenomeAnalysisTK VariantFiltration \
 -R 3_Tms_b3v08.fasta \
 -V Tms.trim2.fb.vcf \
 --genotype-filter-expression 'DP<8||DP>200' \
 --genotype-filter-name 'DP_8-200' \
 --output Tms.trim2.fb_DPfilter.vcf


######################################################################
###################### Filter by QUAL > 30 ###########################
######################################################################
	
	- QUAL > 30 : prob of incorrect read = 1 in 1000; base call accuracy = 99.9%
	- Use home made python script

#! python
import sys
import os
import vcf

vcf_reader = vcf.Reader(open("Tms.alprim.vcf", 'r'))
vcf_writer = vcf.Writer(open('Tms.py.vcf', 'w'), vcf_reader)
# record = vcf_reader.next()
# print record.POS

## we can combine filtering options from different fields (e.g. INFO and FORMAT:)
#for record in vcf_reader:
#    if record.INFO['DP']>10 and record.QUAL > 30:
#        vcf_writer.write_record(record)

## to filter by QUAL
for record in vcf_reader:
    if record.QUAL > 30:
        vcf_writer.write_record(record)


######################################################################
###################### Break MNPs into SNPs ##########################
######################################################################

## path to vcfallelicprimitives
alprim="/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives"

## command line
eval $alprim -kg Tms.QUALpy.vcf > Tms.fb_posvcflib.vcf
eval $alprim -kg Tms.trim2.QUALpy.vcf > Tms.trim2_posvcflib.vcf
eval $alprim -kg Tms.trim3.QUALpy.vcf > Tms.trim3_posvcflib.vcf


######################################################################
##################### Filter by missing data #########################
######################################################################

	- exclude all sites with 25% or more missing genotype

vcftools --recode --recode-INFO-all --vcf Tms.trim3_posvcflib.vcf --max-missing 0.75 --out Tms.trim3missfilt 
vcftools --recode --recode-INFO-all --vcf Tms.trim2_posvcflib.vcf --max-missing 0.75 --out Tms.trim2missfilt
vcftools --recode --recode-INFO-all --vcf Tms.fb_posvcflib.vcf --max-missing 0.75 --out Tms.fbmissfilt


######################################################################
###################### Filter by allelic no ##########################
######################################################################

	- keep Only biallelic SNPs

grep -v 'TYPE=snp,' Tms.trim3missfilt.recode.vcf > Tms.trim3.bial.vcf
   
grep -v 'TYPE=snp,' Tms.fbmissfilt.recode.vcf > Tms.fb.bial.vcf
grep -v 'TYPE=ins' Tms.fb.bial.vcf > Tms.fb.bial2.vcf 
grep -v 'TYPE=del' Tms.fb.bial2.vcf > Tms.fb.bial3.vcf 


grep -v 'TYPE=snp,' Tms.trim2missfilt.recode.vcf > Tms.trim2.bial.vcf
grep -v 'TYPE=ins' Tms.trim2.bial.vcf > Tms.trim2.bial2.vcf 
grep -v 'TYPE=del' Tms.trim2.bial2.vcf > Tms.trim2.bial3.vcf 

grep -v 'TYPE=snp,' Tms.trim3missfilt.recode.vcf > Tms.trim3.bial.vcf
grep -v 'TYPE=ins' Tms.trim3.bial.vcf > Tms.trim3.bial2.vcf 
grep -v 'TYPE=del' Tms.trim3.bial2.vcf > Tms.trim3.bial3.vcf 

######################################################################
########### Calculate intersection between stacks and FB #############
######################################################################

## make bed file
module add Bioinformatics/Software/vital-it
#module avail
module add UHTS/Analysis/plink/1.90
plink --vcf populations.snps.vcf --out stacks --make-bed --allow-extra-chr

## on my laptop, calculate intersection
/mnt/c/Users/User/Softwares/vcflib/bin/vcfintersect






######################################################################
########################## Calculate LD ##############################
######################################################################


########### To calculate LD we also need the information of the chromosome correspondance
### I will use the linkage map Kamil did and convert scaf to cr in R
## by Kamil:
## The final anchoring of scaffolds to linage groups.
## We anchor only scfs longer than 10000 bp and we anchor only 75% of the best mapping (measured by fraction of scaffold mapping somewhere).
## The scaffolds that are not in the list were not anchored (*_anchored_scfs.tsv files)
## I also share the unfiltered tables of all the scaffolds mapping to individual linkage groups (_scf_lg_mapping_overview.tsv)
## Available here:
## ftp://ftpmrr.unil.ch/AsexGenomeEvol/timema/final_references/b3v08_anchoring_to_LGs/
## More details are here:
## https://github.com/AsexGenomeEvol/timema_assembly/tree/master/H_genome_alignment

## I will discard the scafs that do not have a match
## in R:
# merge scaf list with vcf
test <- merge(tms, scaf, by='scafname')
# reorder and sort columns
tmscr <- test[,c(58,2:55)]
tmscr.srt <- tmscr[with(tmscr, order(lg, POS)), ]

## Use plink to calculate LD in two ways:
#### a) with all inds (from both pops) together
#### b) with each pop separated
## to separate the pops from the vcf I will run this on my laptop

/mnt/c/Users/User/Softwares/vcflib/bin/vcfsamplenames
/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples
/mnt/c/Users/User/Softwares/vcflib/bin/vcfstats

/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples Tms.scaf.vcf \
Tms9_P1 Tms8_P1 Tms6_P1 Tms22_P1 Tms4_P1 Tms20_P1 Tms2_P1 Tms14_P1 Tms12_P1 \
Tms11_P1 Tms3_P1 Tms10_P1 Tms5_P1 Tms23_P1 Tms13_P1 Tms7_P1 Tms21_P1 Tms1_P1\
Tms15_P1 Tms16_P1 Tms17_P1 Tms19_P1 Tms18_P1 > Tms.scaf.P2.vcf

/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples Tms.scaf.vcf \
Tms9_P2 Tms8_P2 Tms6_P2 Tms22_P2 Tms4_P2 Tms20_P2 Tms2_P2 Tms14_P2 Tms12_P2 \
Tms11_P2 Tms3_P2 Tms10_P2 Tms5_P2 Tms23_P2 Tms13_P2 Tms7_P2 Tms21_P2 Tms1_P2 \
Tms15_P2 Tms16_P2 Tms17_P2 Tms19_P2 Tms18_P2 > Tms.scaf.P1.vcf

### and then I will run this commands for all vcf files, but for simplicity
## I will just put here the example regarding both pops together

## convert vcf to bed: using plink available in wally
module add Bioinformatics/Software/vital-it
#module avail
module add UHTS/Analysis/plink/1.90
plink --vcf Tms.scaf.vcf --out Tms.scaf --make-bed --allow-extra-chr --recode
# --recode is to make a .map file
# --allow-extra-chr is to allow weird CHROM names
# this command will produce 8 files (.map, .nosex, .bed, .bim, .fam, .ped, .log)

### calculate r2
plink --file Tms.scaf --r2 --allow-extra-chr




## options:
# 'with-freqs' adds MAF columns to table-formatted reports.



## IBS (identity-by-state) similarity matrix
# For the N individuals in a sample, to create a N x N matrix of genome-wide average IBS pairwise identities: 
plink --file mydata --cluster --matrix 

# creates the file
plink.mibs

# which contains a square, symmetric matrix of the IBS distances for all pairs of individuals.
# These values range, in theory, from 0 to 1. In practice, one would never expect to observe values near 0
# -- even completely unrelated individuals would be expected to share a very large proportion of the genome
# identical by state by chance alone (i.e. as opposed to identity by descent). A value of 1 would indicate a MZ twin pair,
# or a sample duplication. More details on pairwise relatedness can be obtained by using the --genome command.

# The default behavior of --matrix to to output similarities (proportions of alleles IBS).
# To generate a distance matrix (1-IBS) then use the command
plink --file mydata --cluster --distance-matrix
# instead. This will generate a file
plink.mdist











vcf_reader = vcf.Reader(open("Tms.alprim.vcf", 'r'))
vcf_writer = vcf.Writer(open('Tms.pyfilt2.vcf', 'w'), vcf_reader)
for record in vcf_reader:
	for call in record:
		#print(call.data.AD)
		depth=call.data.AD
		print(depth)
# only use biallelic SNPs		
		if len(depth) and sum(depth[0:])>9:
			#vcf_writer.write_record(record)
			print(record)
		else:
			continue






module load UHTS/Quality_control/qualimap/2.2.1
qualimap bamqc -nt 8 -bam Tms9_P2-trim3.filtered.bam -outdir results_folder


GenomeAnalysisTK.jar VariantsToTable \
 -R 3_Tmsb3v08.fasta \
 -V Tms.fb.vcf \
 -F CHROM -F POS -GF GT -GF DP \
 -o Tms.fb.DP.table

 




