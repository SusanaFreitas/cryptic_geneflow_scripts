## RAD analyses ##

useful paths:
reference genomes > ftp://ftpmrr.unil.ch/AsexGenomeEvol/timema/

## IMPORTANT INFO ##
## whenever installing an R package in WALLY I will have to download it to my local folder
## here is an example (in R):
install.packages("ggplot2", lib="/users/sfreitas1/R")
library("ggplot2", lib.loc="/users/sfreitas1/R")


######################################################################
######################## SUMMARY PIPELINE ############################
######################################################################


1) Remove reads that failed Casava files
	script: removereads.sh

2) Read quality
	script: fastqc.sh

3) Check that the barcode and the RAD cutsite are intact, and demultiplexing of the data.
	script: process_stacks.sh

4) cloneFilter to remove PCR duplicates # I won't need this, since there wasn't a step to mark the PCR duplicates.
	skip this step


## after realising the BWA was aligning very short reads (with soft clip alignment), I decided to follow a different strategy:
## trim > BWA > FreeBayes

5) TRIM ADAPTORS WITH CUTADAPT

6) Alignment - BWA 


Alignment : BWA better than bowtie (that leaves mores reads out, but test which is best)
	script: 05-mapreads.sh


	helpful oneliners:
	- repeat the same line 88 times in a file
while read line; do for i in {1..88}; do echo "$line"; done; done < inds.end > file


6) SAMTOOLS: sort, filter only aligned reads and index samples (read groups are added during the bwa alignment)
	script: 06-sortfilter.sh

7.1 ) STACKS

filter MAPQ > 30

Call SNPs

7.2 ) freebayes
- Freebayes does not call only SNPS. The vcf will have to be filtered:
	- keep Only SNPs (break MNPs - multi nucleotide polymorphisms- into SNPs)




8) Filtering
## I will also count the number of reads per position, so that I can decide an appropriate DP cutoff.

8.1) FILTER BY 8 < DP < 200

8.2) FILTER BY QUAL > 30

8.3) Break MNPs into SNPs

8.4) FILTER BY missing data < 25%

8.5) FILTER BY allelic no (keep only SNPs)

8.6) Select only SNPs that fall into the overlap between aligned scaffolds with Nosil's genome - these are the SNPs that have lg coordinates and we can use to calculate LD decay





## code names (by Kamil)

The code for every species consist of sister pair number (1-5), `_T` and the first and the last letter of the species name. A following tree visualize phylogeny and sexual reproduction modes

```
               ___ T. poppensis      1_Tps ♀♂
              /  
             /\___ T. douglasi       1_Tdi ♀
            /
           /\  ___ T. californicum   2_Tcm ♀♂
          /  \/
         /    \___ T. shepardi       2_Tsi ♀
        /\
       /  \   ____ T. cristinae      3_Tce ♀♂
      /    \ /
      \     \_____ T. monikensis     3_Tms ♀
       \
        \      ___ T. bartmani       4_Tbi ♀♂
         \    /
          \  /\___ T. tahoe          4_Tte ♀
           \/
            \  ___ T. podura         5_Tpa ♀♂
             \/  
              \___ T. genevieve      5_Tge ♀
```




 
############################################################################
##################### 5) TRIM ADAPTORS WITH CUTADAPT #######################
############################################################################

# during the analyses Darren (and then I confirmed it in my data) found a problem of adapter contamination.
# This caused that the bwa-mem called several softed-clipping reads (alignments) that belonged to the adapter.
# However, when observing the bam files I found that the reads with the softclipped alignments would map
# into the wrong places, giving a SNP whereas reads without adapters wouldn't present that SNP.

# To trim a 3’ adapter, the basic command-line for Cutadapt is:
# cutadapt -a AACCGGTT -o output.fastq input.fastq

# the original Illumina adapter is : AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC.
# However, I got this message for ALL reads in the output file of the 
# first Cutadapt run: 'The adapter is preceded by "A" extremely often'
# To fix the problem I added "A" to the beginning of the adapter sequence and re-ran Cutadapt.
# Also, I eliminated all sequences smaller than 80 bp: -m 80


for file in *.fq.gz; do
        cutadapt -a AAGATCGGAAGAGCACACGTCTGAACTCCAGTCAC -m 80 -o $file-trim3.fq.gz $file;
done

### after some comparisons I will use the trim3 filtering and trimming parameters
# since it was the most conservative, without losing many SNPs
# and I would rather have less SNPs, but correct.



#########################################################################
###### 8) OBSERVE THE NUMBER OF READS PER POSITION IN THE fb vcfs #######
#########################################################################

### To decide how to filter the positions, I will plot the read distribution
# per variant and decide the cutoff according to the 10 and 99 quantiles.

#### gatk ####
GenomeAnalysisTK VariantsToTable \
 -R 3_Tms_b3v08.fasta \
 -V Tms.trim2.fb.vcf \
 -F CHROM -F POS -GF GT -GF DP \
 --output Tms.trim2.fb.DP.table

#### BASH ####
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.trim2.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done
for ((i=3; i<=96; i +=2)); do cut -f $i,$((i+1)) Tms.trim3.fb.DP.table | awk '$1 != "./." {print $2}' > $i.DP; done

#### R ####
# define the file names list (10 samples here) 
nameList <- c()
for (i in 3:96) { # 21 - odd number for 10 samples 
  if (i %% 2 ==1) nameList <- append(nameList, paste(i, ".DP", sep=""))
}

qlist <- matrix(nrow = 47, ncol = 3) # define number of samples (10 samples here)
qlist <- data.frame(qlist, row.names=nameList)
colnames(qlist)<-c('5%', '10%', '99%')

#jpeg("Tms.fb.DP.jpeg", height=1600, width=1200)
pdf("Tms.trim3.fb.DP.pdf", height=20, width=15)
par(mar=c(1, 1, 1, 1), cex=1.5, mfrow=c(24,4)) # define number of plots for your sample
for (i in 1:32) {
  DP <- read.table(nameList[i], header = T)
  qlist[i,] <- quantile(DP[,1], c(.05, .1, .99), na.rm=T)
  d <- density(DP[,1], from=0, to=100, bw=1, na.rm =T)
  plot(d, xlim = c(0,100), main=nameList[i], col="blue", xlab = dim(DP)[1], lwd=2)
  abline(v=qlist[i,c(1,3)], col='red', lwd=3)
}
dev.off()

write.table(qlist, "GVCFall.DP.percentiles.txt")


##############################################################################
################ 8.1) Filter by DP - "DP < 8 || DP > 200" ####################
##############################################################################

## but first we need to create a dictionary for the fasta reference with Picard
module load UHTS/Analysis/picard-tools/2.9.0
picard-tools CreateSequenceDictionary REFERENCE=3_Tce_b3v08.fasta OUTPUT=3_Tce_b3v08.dict
picard-tools CreateSequenceDictionary REFERENCE=3_Tcm_b3v08.fasta OUTPUT=3_Tcm_b3v08.dict

## and samtools faidx
#samtools faidx 3_Tce_b3v08.fasta
#samtools faidx 2_Tcm_b3v08.fasta


##### - keep reads DP > 8 and DP < 200
#### gatk ####
GenomeAnalysisTK VariantFiltration \
 -R 3_Tms_b3v08.fasta \
 -V Tms.trim2.fb.vcf \
 --genotype-filter-expression 'DP<8||DP>200' \
 --genotype-filter-name 'DP_8-200' \
 --set-filtered-genotype-to-no-call\
 --output Tms.trim2.fb_DPfilter.vcf

## OPTIONS:
## --set-filtered-genotype-to-no-call : used this to set the filtered genotypes (the ones that less than 8 > DP > 200)
## to ./.
## https://gatkforums.broadinstitute.org/gatk/discussion/7577/removing-variants-based-on-the-format-field

## I had a problem with this script and I was getting constant 'invalid argument' errors.
## I solved it by removing all spaces in between the formal arguments...
# http://selectvariants1.rssing.com/chan-9504484/all_p2.html




###########################################################################
###################### 8.2) Filter by QUAL > 30 ###########################
###########################################################################
	
	- QUAL > 30 : prob of incorrect read = 1 in 1000; base call accuracy = 99.9%
	- Use home made python script

#! python
import sys
import os
import vcf

vcf_reader = vcf.Reader(open("Tms.alprim.vcf", 'r'))
vcf_writer = vcf.Writer(open('Tms.py.vcf', 'w'), vcf_reader)
# record = vcf_reader.next()
# print record.POS

## we can combine filtering options from different fields (e.g. INFO and FORMAT:)
#for record in vcf_reader:
#    if record.INFO['DP']>10 and record.QUAL > 30:
#        vcf_writer.write_record(record)

## to filter by QUAL
for record in vcf_reader:
    if record.QUAL > 30:
        vcf_writer.write_record(record)



######################################################################
################### 8.3) Break MNPs into SNPs ########################
######################################################################

usage: /usr/lib/vcflib/bin/vcfallelicprimitives [options] [file]

options:
    -m, --use-mnps          Retain MNPs as separate events (default: false).
    -t, --tag-parsed FLAG   Tag records which are split apart of a complex allele with this flag.
    -L, --max-length LEN    Do not manipulate records in which either the ALT or
                            REF is longer than LEN (default: 200).
    -k, --keep-info         Maintain site and allele-level annotations when decomposing.
                            Note that in many cases, such as multisample VCFs, these won't
                            be valid post-decomposition.  For biallelic loci in single-sample
                            VCFs, they should be usable with caution.
    -g, --keep-geno         Maintain genotype-level annotations when decomposing.  Similar
                            caution should be used for this as for --keep-info.

If multiple allelic primitives (gaps or mismatches) are specified in
a single VCF record, split the record into multiple lines, but drop all
INFO fields (unless you choose the -kg options).  Does not handle genotypes (yet).  MNPs are split into
multiple SNPs unless the -m flag is provided.  Records generated by splits have th

--use-best-n-alleles all (default) --min-mapping-quality 30 --min-coverage 5
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.fb_DPfilter.vcf > Tms.fb_posvcflib.vcf
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.trim2.fb_DPfilter.vcf > Tms.trim2.fb_posvcflib.vcf
/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives -kg Tms.trim3.fb_DPfilter.vcf > Tge.trim3.fb_posvcflib.vcf


## path to vcfallelicprimitives
alprim="/scratch/temporary/sfreitas/softwares/vcflib/bin/vcfallelicprimitives"

## command line: Tms
eval $alprim -kg Tms.QUALpy.vcf > Tms.fb_posvcflib.vcf
eval $alprim -kg Tms.trim2.QUALpy.vcf > Tms.trim2_posvcflib.vcf
eval $alprim -kg Tms.trim3.QUALpy.vcf > Tms.trim3_posvcflib.vcf

## command line: Tge
vcflib vcfallelicprimitives -kg Tge.trim2-test.py.out.vcf > Tge.trim2-test_posvcflib.vcf
vcflib vcfallelicprimitives -kg Tge.trim2.py.out.vcf > Tge.trim2_posvcflib.vcf
vcflib vcfallelicprimitives -kg Tge.trim3.py.out.vcf > Tge.trim3_posvcflib.vcf

vcflib vcfallelicprimitives -kg Tms.fb.QUALpy.vcf > Tms.fb_posvcflib.vcf
vcflib vcfallelicprimitives -kg Tms.trim2.QUALpy.vcf > Tms.trim2_posvcflib.vcf
vcflib vcfallelicprimitives -kg Tms.trim3.QUALpy.vcf > Tms.trim3_posvcflib.vcf

vcflib vcfallelicprimitives -kg Tce_QUALpy.vcf > Tce_posvcflib.vcf
vcflib vcfallelicprimitives -kg Tcm_QUALpy.vcf > Tcm_posvcflib.vcf




###########################################################################
##################### 8.4) Filter by missing data #########################
###########################################################################

	- exclude all sites with 25% or more missing genotype

vcftools --recode --recode-INFO-all --vcf Tms.trim3_posvcflib.vcf --max-missing 0.75 --out Tms.trim3missfilt 
vcftools --recode --recode-INFO-all --vcf Tms.trim2_posvcflib.vcf --max-missing 0.75 --out Tms.trim2missfilt
vcftools --recode --recode-INFO-all --vcf Tms.fb_posvcflib.vcf --max-missing 0.75 --out Tms.fbmissfilt
vcftools --recode --recode-INFO-all --vcf Tge.stacks.DP_filter.vcf --max-missing 0.75 --out Tge.missfilt

vcftools --recode --recode-INFO-all --vcf Tce_posvcflib.vcf --max-missing 0.75 --out Tce_missfilt
vcftools --recode --recode-INFO-all --vcf Tcm_posvcflib.vcf --max-missing 0.75 --out Tcm_missfilt



###########################################################################
###################### 8.5) Filter by allelic no ##########################
###########################################################################

	- keep Only biallelic SNPs

grep -v 'TYPE=snp,' Tms.trim3missfilt.recode.vcf > Tms.trim3.bial.vcf
   
grep -v 'TYPE=snp,' Tcm_missfilt.recode.vcf > Tcm.bial.vcf
grep -v 'TYPE=ins' Tcm.bial.vcf > Tcm.bial2.vcf 
grep -v 'TYPE=del' Tcm.bial2.vcf > Tcm.bial3.vcf 

grep -v 'TYPE=snp,' Tce_missfilt.recode.vcf > Tce.bial.vcf
grep -v 'TYPE=ins' Tce.bial.vcf > Tce.bial2.vcf 
grep -v 'TYPE=del' Tce.bial2.vcf > Tce.bial3.vcf 

grep -v 'TYPE=snp,' Tms.trim2missfilt.recode.vcf > Tms.trim2.bial.vcf
grep -v 'TYPE=ins' Tms.trim2.bial.vcf > Tms.trim2.bial2.vcf 
grep -v 'TYPE=del' Tms.trim2.bial2.vcf > Tms.trim2.bial3.vcf 

grep -v 'TYPE=snp,' Tms.trim3missfilt.recode.vcf > Tms.trim3.bial.vcf
grep -v 'TYPE=ins' Tms.trim3.bial.vcf > Tms.trim3.bial2.vcf 
grep -v 'TYPE=del' Tms.trim3.bial2.vcf > Tms.trim3.bial3.vcf



          #######################################################
####### ~~~~~~~~~~ end of mapping - SNPs calling pipeline ~~~~~~~~~ ########
          #######################################################





#### repeat for sexual species


## more inds than 23 - select the 23 with higher coverage
vcftools --vcf Tce.bial3.vcf --missing-indv --out Tce
vcftools --vcf Tcm.bial3.vcf --missing-indv --out Tcm

### filter only 23 samples - 23 first

vcflib vcfkeepsamples Tce.bial3.vcf tce_m6.bam tce_m41.bam tce_m9.bam tce_m3.bam tce_m37.bam tce_m32.bam \
	tce_m29.bam tce_m8.bam tce_m22.bam tce_m21.bam tce_m1.bam tce_m19.bam tce_m18.bam tce_m2.bam tce_m14.bam \
	tce_m35.bam tce_m34.bam tce_m15.bam tce_m28.bam tce_m20.bam tce_m26.bam tce_m38.bam tce_m13.bam > Tce_sample23.vcf

vcflib vcfkeepsamples Tcm.bial3.vcf tcm_m8.bam tcm_m3.bam tcm_m38.bam tcm_m36.bam tcm_m35.bam tcm_m34.bam \
	tcm_m31.bam tcm_m2.bam tcm_m24.bam tcm_m23.bam tcm_m1.bam tcm_f1.bam tcm_f12.bam tcm_f10.bam tcm_f11.bam \
	tcm_m6.bam tcm_m20.bam tcm_m11.bam tcm_m22.bam tcm_m15.bam tcm_m13.bam tcm_m14.bam tcm_m16.bam > Tcm_sample23.vcf

## filter only SNPs tjat are aligned and have lg coordinates
python3 '/home/susana/Dropbox/Timema_cryptic_geneflow/cryptic_geneflow_scripts/filter_Mummer_snps.py' -i Tcm_sample23.vcf -d 2_Tcm_scf_block_alignment.tsv -o Tcm_alignedcoords.vcf -s Tcm

python3 '/home/susana/Dropbox/Timema_cryptic_geneflow/cryptic_geneflow_scripts/filter_Mummer_snps.py' -i Tce_sample23.vcf -d 3_Tce_scf_block_alignment.tsv -o Tce_alignedcoords.vcf -s Tce


##### Calculate LD
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --vcf Tcm_alignedcoords.vcf --make-bed --out Tcm_alignedcoords.lg --allow-extra-chr --recode
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --file Tcm_alignedcoords.lg --maf 0.2 --recode --out Tcm_alignedcoords.lg.maf --allow-extra-chr --make-bed
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --file Tcm_alignedcoords.lg.maf --r2 inter-chr --ld-window-r2 0 --allow-extra-chr --out Tcm_alignedcoords.lg.maf.inter
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tcm_alignedcoords.lg.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tcm_alignedcoords.lg.maf.decay --allow-extra-chr

/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --vcf Tce_alignedcoords.vcf --make-bed --out Tce_alignedcoords.lg --allow-extra-chr --recode
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --file Tce_alignedcoords.lg --maf 0.2 --recode --out Tce_alignedcoords.lg.maf --allow-extra-chr --make-bed
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --file Tce_alignedcoords.lg.maf --r2 inter-chr --ld-window-r2 0 --allow-extra-chr --out Tce_alignedcoords.lg.maf.inter
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tce_alignedcoords.lg.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tce_alignedcoords.lg.maf.decay --allow-extra-chr
#

## calculate heterozygosity
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '1/0' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '0/1' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '1|0' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '0|1' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '1/1' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '1|1' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '0/0' | wc -l; done
for i in {10..32}; do grep -v '^#' Tcm_alignedcoords.vcf | awk -v i="$i" '{ print $i}' | grep '0|0' | wc -l; done






######################################################################
#################### 8.6) Get Scaffold Coordinates ########################
######################################################################

## from Kamil
cd anywhere/where/Susana/stores/her/project/directories

git clone https://github.com/AsexGenomeEvol/timema_assembly

cd timema_assembly && rm -r data

#scp -r sfreitas@axiom-front1.unil.ch/scratch/axiom/FAC/FBM/DEE/tschwand/default/kjaron/timema_assembly/data timema_assembly .
scp -r /scratch/axiom/FAC/FBM/DEE/tschwand/default/kjaron/timema_assembly/data timema_assembly .

python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 3_Tce 1> data/3_Tce/reference/3_Tce_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 3_Tms 1> data/3_Tms/reference/3_Tms_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 5_Tpa 1> data/5_Tpa/reference/5_Tpa_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 5_Tge 1> data/5_Tge/reference/5_Tge_scf_block_alignment.tsv

python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 1_Tdi 1> data/1_Tdi/reference/1_Tdi_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 1_Tps 1> data/1_Tps/reference/1_Tps_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 2_Tsi 1> data/2_Tsi/reference/2_Tsi_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 2_Tcm 1> data/2_Tcm/reference/2_Tcm_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 4_Tte 1> data/4_Tte/reference/4_Tte_scf_block_alignment.tsv
python3 H_genome_alignment/MUMmer_scfs_block_alignment.py 4_Tbi 1> data/4_Tbi/reference/4_Tbi_scf_block_alignment.tsv
#
#




# The scp step will get you ~20G of Timema related data.
# There is a lot of messy files in there, but there are also all those relevant files you need.
# (you can also get just the mapping files from the cluster, but this is by far easier for bash manipulation)
# 1. you run all the scripts I write from the project directory timema_assembly 
# 2. you store all the relevant data in subdirectory data
# 3. you write all the paths relative and therefore the same script will work both on mine and your computer.





######################################################################
########################## Calculate LD ##############################
######################################################################


########### To calculate LD we also need the information of the chromosome correspondance
### I will use the linkage map Kamil did* and convert scaf to cr in R
## at first I used one without the unchored coordinates, but now I will use anchored
## by Kamil:
## The final anchoring of scaffolds to linkage groups.
## We anchor only scfs longer than 10000 bp and we anchor only 75% of the best mapping (measured by fraction of scaffold mapping somewhere).
## The scaffolds that are not in the list were not anchored (*_anchored_scfs.tsv files)
## I also share the unfiltered tables of all the scaffolds mapping to individual linkage groups (_scf_lg_mapping_overview.tsv)
## Available here:
## ftp://ftpmrr.unil.ch/AsexGenomeEvol/timema/final_references/b3v08_anchoring_to_LGs/
## More details are here:
## https://github.com/AsexGenomeEvol/timema_assembly/tree/master/H_genome_alignment

## I will discard the scafs that do not have a match
## in R:
# merge scaf list with vcf
test <- merge(tms, scaf, by='scafname')
# reorder and sort columns
tmscr <- test[,c(58,2:55)]
tmscr.srt <- tmscr[with(tmscr, order(lg, POS)), ]

## Use plink to calculate LD in two ways:
#### a) with all inds (from both pops) together
#### b) with each pop separated
## to separate the pops from the vcf I will run this on my laptop

/mnt/c/Users/User/Softwares/vcflib/bin/vcfsamplenames
/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples
/mnt/c/Users/User/Softwares/vcflib/bin/vcfstats

/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples Tms.scaf.vcf Tms9_P1 Tms8_P1 Tms6_P1 Tms22_P1 Tms4_P1 Tms20_P1 Tms2_P1 Tms14_P1 Tms12_P1 Tms11_P1 Tms3_P1 Tms10_P1 Tms5_P1 Tms23_P1 Tms13_P1 Tms7_P1 Tms21_P1 Tms1_P1 Tms15_P1 Tms16_P1 Tms17_P1 Tms19_P1 Tms18_P1 > Tms.scaf.P2.vcf

/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples Tms.scaf.vcf Tms9_P2 Tms8_P2 Tms6_P2 Tms22_P2 Tms4_P2 Tms20_P2 Tms2_P2 Tms14_P2 Tms12_P2 Tms11_P2 Tms3_P2 Tms10_P2 Tms5_P2 Tms23_P2 Tms13_P2 Tms7_P2 Tms21_P2 Tms1_P2 Tms15_P2 Tms16_P2 Tms17_P2 Tms19_P2 Tms18_P2 > Tms.scaf.P1.vcf

## or use vcftools on wally
module add Bioinformatics/Software/vital-it

vcftools --vcf Tms.trim3.scafs.srt.vcf --remove samplesPOP1 --recode --recode-INFO-all --out Tms.trim3.scafs.srt.POP1
vcftools --vcf Tms.trim3.scafs.srt.vcf --remove samplesPOP2 --recode --recode-INFO-all --out Tms.trim3.scafs.srt.POP2


### and then I will run this commands for all vcf files, but for simplicity
## I will just put here the example regarding both pops together

## convert vcf to bed: using plink available in wally
module add Bioinformatics/Software/vital-it
#module avail
module add UHTS/Analysis/plink/1.90
plink --vcf Tms.scaf.vcf --out Tms.scaf --make-bed --allow-extra-chr --recode

# --with-freqs to add MAF (minor allele frequency) to the output table
# --recode is to make a .map file
# --allow-extra-chr is to allow weird CHROM names
# this command will produce 8 files (.map, .nosex, .bed, .bim, .fam, .ped, .log)

### recalculate LD in Monikensis P2 without the heterozygote outliers
# Tms1_P2
# Tms17_P2
# Tms19_P2
# Tms22_P2

/mnt/c/Users/User/Softwares/vcflib/bin/vcfremovesamples Tms_alignedcoords_P2.vcf Tms1_P2 Tms17_P2 Tms19_P2 Tms22_P2 > Tms_alignedcoords_P2.noutliers.vcf

./plink --vcf Tms_alignedcoords_P2.noutliers.vcf --out Tms.coord.P2.noutlie --make-bed --allow-extra-chr --recode

## calculate the LD
./plink.exe --bfile Tms.coord.P2.noutlie --maf 0.2 --recode --out Tms.coord.P2.noutlie.maf --allow-extra-chr --make-bed
./plink.exe --file Tms.coord.P2.noutlie.maf --r2 inter-chr --ld-window-r2 0 --allow-extra-chr --out Tms.coord.P2.noutlie.maf.inter
./plink.exe --bfile Tms.coord.P2.noutlie.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.coord.P2.noutlie.maf.decay --allow-extra-chr





./plink.exe --bfile Tms.coord.P2.noutlie --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.coord.P2.noutlie.
### LD decay
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tms.coord.P2.noutlie.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.P2.coord.decay --allow-extra-chr






######################################################################
####################### Calculate LD decay ###########################
######################################################################

### I will be following the pipeline from here: https://www.biostars.org/p/300381/

# To reduce false positive rates and speed up execution time I will filter by MAF
# see here: https://www.staff.ncl.ac.uk/richard.howey/mapthin/introduction.html

/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink

plink --file mydata --maf 0.4 --recode --out mydata-frequent

# calculate r2 intra cr, cr by cr (because it will create a huge output)
# set -ld-window-r2 to 0 (see why here: https://www.biostars.org/p/84443/)
# To get the the LD decay plot you need to do something like the following. First of all -
# generate a text file with two columns - the first is the distance between the two SNPs
# (i.e. BP_B - BP_A, so if the first snp is at position 1000 on the chromosome, and the second
# is at position 2150, the distance is 1150 ) and the second is the corresponding R2 value (your last column).
# So you get a file with R2 values for SNPs certain distances apart. distance R2 5 0.2 5 0.3 67 0.2 67 0.4 67 0.5
# Then for each distance apart, calculate an average R2 (you need to generate a script to do this e.g. 
# in python/perl) i.e. distance average R2 5 0.25 67 0.3667
# Then plot that file to get the LD decay.
# Depending on how many points you have, you may want to using a sliding window average script for the plot.
# In the example, I think this is what they did - in terms of 1kb intervals, i.e. they did a sliding window - 
# with a window size of 1kb and step size of 1kb, and calculated average r2. 

/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tge_alignedcoords_P1.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tge.P1.coord.decay --allow-extra-chr
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tge_alignedcoords_P2.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tge.P2.coord.decay --allow-extra-chr
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tms_alignedcoords_P1.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.P1.coord.decay --allow-extra-chr
/home/susana/SOFTWARES/plink_linux_x86_64_20190617/plink --bfile Tms_alignedcoords_P2.maf --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.P2.coord.decay --allow-extra-chr
## calculate the LD
plink --bfile Tms.scaf.P1.frq --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.scaf.P1.frq
plink --bfile Tms.scaf.P2.frq --r2 --ld-window-r2 0 --ld-window 999999 --ld-window-kb 8000 --out Tms.scaf.P2.frq


LD <- read.table("your_plinkresult.ld", header = T) ##read your .ld data
LD$distancekb <- with (LD, LD$BP_B-LD$BP_A)/1000 ## the distance between snp1 and snp2 in kb
LD$grp <- cut(LD$distancekb, 0:70) ## bin 70kb
r2means <- with (LD, tapply(LD$R2, LD$grp, FUN = mean)) ##r2 mean every 1kb


https://bioinformatics.stackexchange.com/questions/2905/using-plink-to-find-snps-in-ld-linkage-disequilibrium-with-another-set-of-snps
https://www.researchgate.net/post/How_can_I_do_linkage_disequilibrium_LD_test_for_a_list_of_snp
https://www.biostars.org/p/396127/
https://www.biostars.org/p/268141/

https://www.biostars.org/p/113037/
https://www.biostars.org/p/274562/
https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-8-428
https://www.cog-genomics.org/plink/1.9/ld



### calculate r2
plink --file Tms.scaf --r2 --allow-extra-chr




## calculate r2 in the divided by pop file
plink --allow-extra-chr --make-bed --out Tms.scaf.P2 --recode --remove P1 --vcf Tms.scaf.vcf

plink --bfile QC_file --het --out QC_het



  CHR_A.........BP_A.SNP_A..CHR_B.........BP_B.SNP_B...........R2




### convert output into something readable with R (pain in the ass)
cp raw-files/Tms.interLD.P1.ld tms.inter.p1
# working file: tms.inter.p1
sed -i 's/ /+/g' tms.inter.p1
# remove the last character
sed -i 's/.$//' tms.inter.p1

sed -i 's/+++++++++++++++/\t/g' tms.inter.p1 
sed -i 's/++++++++++++++/\t/g' tms.inter.p1 
sed -i 's/+++++++++++++/\t/g' tms.inter.p1 
sed -i 's/++++++++++++/\t/g' tms.inter.p1

sed -i 's/+++++++++++/\t/g' tms.inter.p1
sed -i 's/++++++++++/\t/g' tms.inter.p1
sed -i 's/+++++++++/\t/g' tms.inter.p1
sed -i 's/++++++++/\t/g' tms.inter.p1
sed -i 's/+++++++/\t/g' tms.inter.p1
sed -i 's/++++++/\t/g' tms.inter.p1

sed -i 's/+++++/\t/g' tms.inter.p1
sed -i 's/++++/\t/g' tms.inter.p1
sed -i 's/+++/\t/g' tms.inter.p1
sed -i 's/++/\t/g' tms.inter.p1
sed -i 's/+/\t/g' tms.inter.p1

# some '.' were left without tabs between them and the next column. To correct that:
sed -i 's/\.l/\.\tl/g' tms.inter.p1

# remove \t in the beginning of the line
sed -i 's/^\t//g' tms.inter.p1










/scratch/wally/FAC/FBM/DEE/tschwand/default/sfreitas/Softwares/vcflib/bin/vcfstats Tge.trim3.fb-test_DPfilter.vcf > Tge.trim3.stats

bFst
bFst is a Bayesian approach to Fst.  Importantly bFst account for genotype uncertainty in the model using genotype likelihoods.
     For a more detailed description see: Holsinger et al. Molecular Ecology Vol 11, issue 7 2002.  The likelihood function has been 
     modified to use genotype likelihoods provided by variant callers. There are five free parameters estimated in the model: each 
     subpopulation's allele frequency and Fis (fixation index, within each subpopulation), a free parameter for the total 
	population's allele frequency, and Fst.

pFst
pFst is a probabilistic approach for detecting differences in allele frequencies between two populations.

genotypeSummary
Summarizes genotype counts for bi-allelic SNVs and indel 

hapLrt
HapLRT is a likelihood ratio test for haplotype lengths.  The lengths are modeled with an exponential distribtuion.  
     The sign denotes if the target has longer haplotypes (1) or the background (-1).

iHS
     iHS calculates the integrated ratio of haplotype decay between the reference and non-reference allele.
vcfplottstv.sh
plotBfst.R
nohup R --vanilla < plotPfst --args pFst.txt

plotHaplotypes.R
plotHapLrt.R
plotHaps
plotPfst.R
plot_roc.r
plotSmoothed.R
plotWCfst.R
plotXPEHH.R
vcfsitesummarize
vcfsnps
vcfsort
vcfstats
vcfstreamsort
vcf_strip_extra_headers
vcfuniq
vcfuniqalleles
vcfunphase
vcfvarstats
wcFst



######################################################################
########### Calculate intersection between stacks and FB #############
######################################################################

## make bed file
module add Bioinformatics/Software/vital-it
#module avail
module add UHTS/Analysis/plink/1.90
plink --vcf populations.snps.vcf --out stacks --make-bed --allow-extra-chr


## To test whether the overlap between vcf files produced by STACKS and FB I calculated intersection between both files.
## I tried vcflib at first (vcfintersect) but it gave me an empty combined.vcf file.
## on my laptop, calculate intersection
/mnt/c/Users/User/Softwares/vcflib/bin/vcfintersect
## had to make new bed files (non binary)
### make bed files
awk -f BEGIN { OFS="\t"; } { if ( $0 !~ /\#/ ) {print $1, $2-1, $2;} } Tms.scaf.vcf > scaf.bed
sed -e 's/chr//' Tms.scaf.vcf | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2,$4"/"$5,"+"}}' > scaf.bed
sed -e 's/chr//' populations.snps.vcf | awk '{OFS="\t"; if (!/^#/){print $1,$2-1,$2,$4"/"$5,"+"}}' > stacks-good.bed

## Then I tried bcftools
bcftools isec -p results/ populations.snps.vcf.gz Tms.scaf.vcf.gz

## But I also couldnt make it to work

## Then I tried GATK - CombineGVCFs (it is a recent tool that replaced CombineVariants)

## but first we need to create a dictionary for the fasta reference with Picard
module load UHTS/Analysis/picard-tools/2.9.0
picard-tools CreateSequenceDictionary REFERENCE=3_Tms_b3v08.fasta OUTPUT=3_Tms_b3v08.dict

## and index the reference
module add UHTS/Analysis/samtools/1.8
samtools faidx 3_Tms_b3v08.fasta

## run the CombineGVCFs tool
module load UHTS/Analysis/GenomeAnalysisTK/4.1.0.0
GenomeAnalysisTK CombineGVCFs \
   -R 3_Tms_b3v08.fasta \
   --variant stacks.snps.vcf \
   --variant Tms.scaf.vcf \
   -O output_combined.vcf

## But it was failing (it gave an error about the stacks vcf file). After running vcf-validator (from vcftools)
module add UHTS/Analysis/vcftools/0.1.15
vcf-validator populations.snps.vcf
## I noticed the vcf lacked the reference and contigs info in the header. So I added that (with oneliners and creative unixing)
## and ran again GATK CombineGVCFs


((TO BE CONTINUED)))) (( WAITING FOR THE SCRIPT TO FINISH)) -
- FAILED TO TO REACHING TIME LIM - INCREASED TIME LIM (from normal queue to long in WALLY)

VCFtools:

vcf-isec -f -n =4 input1.vcf.gz input2.vcf.gz input3.vcf.gz input4.vcf.gz > output.vcf

GATK:

GenomeAnalysisTK.jar -T CombineVariants -R refSequence.fasta --variant input1.vcf --variant input2.vcf --variant input3.vcf --variant input4.vcf -o output_combined.vcf
GenomeAnalysisTK.jar -T SelectVariants -R refSequence.fasta -V:variant output_combined.vcf -select 'set=="Intersection";' -o output_intersected.vcf













###### real scripts
#########################################
####### plot LD inter cr for POP1 #######
#########################################

#### in R
[ cd /scratch/wally/FAC/FBM/DEE/tschwand/default/sfreitas/geneflow/07-stacks/Tms/vcf-stats/divpop ]

# make violin plot
install.packages("ggplot2", lib="/users/sfreitas1/R")
install.packages("crayon", lib="/users/sfreitas1/R")
install.packages("vctrs", lib="/users/sfreitas1/R")
install.packages("backports", lib="/users/sfreitas1/R")
install.packages("withr", lib="/users/sfreitas1/R")
install.packages("labeling", lib="/users/sfreitas1/R")
install.packages("digest", lib="/users/sfreitas1/R")
install.packages("dplyr", lib="/users/sfreitas1/R")
install.packages("fansi", lib="/users/sfreitas1/R")
install.packages("utf8", lib="/users/sfreitas1/R")
install.packages("cli", lib="/users/sfreitas1/R")

library("cli", lib.loc="/users/sfreitas1/R")
library("utf8", lib.loc="/users/sfreitas1/R")
library("fansi", lib.loc="/users/sfreitas1/R")
library("digest", lib.loc="/users/sfreitas1/R")
library("labeling", lib.loc="/users/sfreitas1/R")
library("withr", lib.loc="/users/sfreitas1/R")
library("backports", lib.loc="/users/sfreitas1/R")
library("vctrs", lib.loc="/users/sfreitas1/R")
library("crayon", lib.loc="/users/sfreitas1/R")
library("ggplot2", lib.loc="/users/sfreitas1/R")
library("dplyr", lib.loc="/users/sfreitas1/R")

# read in the readable file (after sed/bash tweaking)
p1in <- read.delim("tms.inter.p1", header=F)
# changing the collumns names
colnames(p1in) <- c("CHR_A", "BP_A", "SNP_A", "CHR_B", "BP_B", "SNP_B", "R2")

# make column with chr-chr
p1in$inter <- paste(p1in$CHR_A,'-',p1in$CHR_B, sep='')

# confirm if we are doing it correctly
chr_unq <- unique(p1in$inter)
length(chr_unq)

### GOOD!! continue :)

# to make subset of data (example)
lg1 <- subset(p1in, CHR_A %in% c("lg1"))

## how many cr interactions we have
"lg1-lg1", "lg1-lg2", "lg1-lg3", "lg1-lg4", "lg1-lg5", "lg1-lg6",
"lg1-lg7", "lg1-lg8", "lg1-lg9", "lg1-lg10", "lg1-lg11", "lg1-lg12", "lg1-lgX"

## example of the violin plot
pdf(file="lg1-all.pdf")
myplot <- ggplot(lg1) + 
	geom_violin(aes(x= inter, y = R2, colour=inter)) +
	facet_wrap(~inter, scales = "free")
print(myplot)
dev.off()

## reorder x axis labels
p1in$inter2 <- factor(p1in$inter, levels = c("lg1-lg1", "lg2-lg2", "lg3-lg3", "lg4-lg4", "lg5-lg5", "lg6-lg6", "lg7-lg7", "lg8-lg8",
				"lg9-lg9", "lg10-lg10", "lg11-lg11", "lg12-lg12", "lgX-lgX",
				"lg1-lg2", "lg1-lg3", "lg1-lg4", "lg1-lg5", "lg1-lg6", "lg1-lg7", "lg1-lg8", "lg1-lg9",
				"lg1-lg10", "lg1-lg11", "lg1-lg12", "lg1-lgX",
				"lg2-lg3", "lg2-lg4", "lg2-lg5", "lg2-lg6", "lg2-lg7", "lg2-lg8", "lg2-lg9", "lg10-lg2",
				"lg11-lg2", "lg12-lg2", "lg2-lgX",
				"lg3-lg4", "lg3-lg5", "lg3-lg6", "lg3-lg7", "lg3-lg8", "lg3-lg9", "lg10-lg3", "lg11-lg3",
				"lg12-lg3", "lg3-lgX",
				"lg4-lg5", "lg4-lg6", "lg4-lg7", "lg4-lg8", "lg4-lg9", "lg10-lg4", "lg11-lg4", "lg12-lg4",
				"lg4-lgX",
				"lg5-lg6", "lg5-lg7", "lg5-lg8", "lg5-lg9", "lg10-lg5", "lg11-lg5", "lg12-lg5", "lg5-lgX",
				"lg6-lg7", "lg6-lg8", "lg6-lg9", "lg10-lg6", "lg11-lg6", "lg12-lg6", "lg6-lgX",
				"lg7-lg8", "lg7-lg9", "lg10-lg7", "lg11-lg7", "lg12-lg7", "lg7-lgX",
				"lg8-lg9", "lg10-lg8", "lg11-lg8", "lg12-lg8", "lg8-lgX",
				"lg10-lg9", "lg11-lg9", "lg12-lg9", "lg9-lgX",
				"lg10-lg11", "lg10-lg12", "lg10-lgX",
				"lg11-lg12", "lg11-lgX",
				"lg12-lgX"))






# make error bars
errbar_lims = group_by(p1in, inter2) %>%
summarize(mean=mean(R2), se=sd(R2)/sqrt(n()),
upper=mean+(2*se), lower=mean-(2*se))

##### final commands to make the main plot: all pairwise comparisons
mean_se_violin =  ggplot() + 
	geom_violin(data=p1in, aes(x= inter2, y = R2, colour=inter2)) +
	geom_point(data=p1in, aes(x= inter2, y=R2), stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, size=1) +
	geom_errorbar(aes(x=errbar_lims$inter2, ymax=errbar_lims$upper, ymin=errbar_lims$lower), stat='identity', width=.25) +
	theme_minimal() +
	theme(axis.text.x = element_text(angle = 45, size=4,  hjust=1), legend.position = "none")

pdf(file="P1.cr-all-mean-label.pdf")
print(mean_se_violin)
dev.off()


#########################################
####### plot LD inter cr for POP2 #######
#########################################

# read in the readable file (after sed/bash tweaking)
p2in <- read.delim("tms.inter.p2", header=T)
# changing the collumns names
# colnames(p2in) <- c("CHR_A", "BP_A", "SNP_A", "CHR_B", "BP_B", "SNP_B", "R2")

# make column with chr-chr
p2in$inter <- paste(p2in$CHR_A,'-',p2in$CHR_B, sep='')

# for (i in c("lg1", "lg2", "lg3", "lg4", "lg5", "lg6", "lg7", "lg8", "lg9", "lg10", "lg11", "lg12", "lgX")) {

# lgi <- subset(p2in, CHR_A %in% c(i))

## reorder x axis labels
p2in$inter2 <- factor(p2in$inter, levels = c("lg1-lg1", "lg2-lg2", "lg3-lg3", "lg4-lg4", "lg5-lg5", "lg6-lg6", "lg7-lg7", "lg8-lg8",
				"lg9-lg9", "lg10-lg10", "lg11-lg11", "lg12-lg12", "lgX-lgX",
				"lg1-lg2", "lg1-lg3", "lg1-lg4", "lg1-lg5", "lg1-lg6", "lg1-lg7", "lg1-lg8", "lg1-lg9",
				"lg1-lg10", "lg1-lg11", "lg1-lg12", "lg1-lgX",
				"lg2-lg3", "lg2-lg4", "lg2-lg5", "lg2-lg6", "lg2-lg7", "lg2-lg8", "lg2-lg9", "lg10-lg2",
				"lg11-lg2", "lg12-lg2", "lg2-lgX",
				"lg3-lg4", "lg3-lg5", "lg3-lg6", "lg3-lg7", "lg3-lg8", "lg3-lg9", "lg10-lg3", "lg11-lg3",
				"lg12-lg3", "lg3-lgX",
				"lg4-lg5", "lg4-lg6", "lg4-lg7", "lg4-lg8", "lg4-lg9", "lg10-lg4", "lg11-lg4", "lg12-lg4",
				"lg4-lgX",
				"lg5-lg6", "lg5-lg7", "lg5-lg8", "lg5-lg9", "lg10-lg5", "lg11-lg5", "lg12-lg5", "lg5-lgX",
				"lg6-lg7", "lg6-lg8", "lg6-lg9", "lg10-lg6", "lg11-lg6", "lg12-lg6", "lg6-lgX",
				"lg7-lg8", "lg7-lg9", "lg10-lg7", "lg11-lg7", "lg12-lg7", "lg7-lgX",
				"lg8-lg9", "lg10-lg8", "lg11-lg8", "lg12-lg8", "lg8-lgX",
				"lg10-lg9", "lg11-lg9", "lg12-lg9", "lg9-lgX",
				"lg10-lg11", "lg10-lg12", "lg10-lgX",
				"lg11-lg12", "lg11-lgX",
				"lg12-lgX"))

# make error bars
errbar_lims = group_by(p2in, inter2) %>%
summarize(mean=mean(R2), se=sd(R2)/sqrt(n()),
upper=mean+(2*se), lower=mean-(2*se))


mean_se_violin = ggplot() + 
	geom_violin(data=p2in, aes(x= inter2, y = R2, colour=inter2)) +
	geom_point(data=p2in, aes(x= inter2, y=R2), stat="summary", fun.y=mean, fun.ymax=mean, fun.ymin=mean, size=1) +
	geom_errorbar(aes(x=errbar_lims$inter2, ymax=errbar_lims$upper, ymin=errbar_lims$lower), stat='identity', width=.25) +
	theme_minimal() +
	theme(axis.text.x = element_text(angle = 45, size=4, hjust=1), legend.position = "none")
	
pdf(file="P2.cr-all-mean-label.pdf")
print(mean_se_violin)
dev.off()




#########################################
############# calculate HET #############
#########################################

## To get all the observed hom and het positions (HOM1 and HOM2)
vcftools --vcf Tms.trim3.scafs.vcf --hardy --out Tms.trim3
vcftools --vcf Tms.trim2.scafs.vcf --hardy --out Tms.trim2
vcftools --vcf Tms.fb.scafs.vcf --hardy --out Tms.fb
vcftools --vcf Tge.scafs.vcf --hardy --out Tms.trim3
## To get the total heterozygosity per individual 
vcftools --vcf Tms.trim3.scafs.vcf --het --out Tms.trim3
vcftools --vcf Tms.trim2.scafs.vcf --het --out Tms.trim2
vcftools --vcf Tms.fb.scafs.vcf --het --out Tms.fb

## options:
# 'with-freqs' adds MAF columns to table-formatted reports.

### this command will calculate an approximate of the het/total positions ratio
## excluding the reference homozygous positions > 0/0 and 0|0
vcflib vcfhethomratio file.vcf

## I can also calculate the same ratio, the values are not exactly the same (??) but approximate
## I will use the manual calculated ratio (because I cannot explain what happens in vcflib
## and why is it different than my manually calculated ratio)

### calculate heterozygosity - counts of het positions in the vcf files
for i in {10..32}; do grep -v '^#' asex3.vcf | awk -v i="$i" '{ print $i}' | grep '1/0' | wc -l; done
for i in {10..32}; do grep -v '^#' asex3.vcf | awk -v i="$i" '{ print $i}' | grep '0/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|1' | wc -l; done

### calculate homozygosity - counts of hom positions in the vcf files
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.fb.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim2.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1/1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0/0' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '1|1' | wc -l; done
for i in {10..55}; do grep -v '^#' Tms.trim3.scafs.vcf | awk -v i="$i" '{ print $i}' | grep '0|0' | wc -l; done




for i in {10..32}; do grep -v '^#' selfing-highrecomb.vcf | awk -v i="$i" '{ print $i}' | grep '1|0' | wc -l; done
for i in {10..32}; do grep -v '^#' selfing-highrecomb.vcf | awk -v i="$i" '{ print $i}' | grep '0|1' | wc -l; done
for i in {10..32}; do grep -v '^#' selfing-highrecomb.vcf | awk -v i="$i" '{ print $i}' | grep '0|0' | wc -l; done
for i in {10..32}; do grep -v '^#' selfing-highrecomb.vcf | awk -v i="$i" '{ print $i}' | grep '1|1' | wc -l; done






######################################################################
#################### Simulate Asexual Genomes ########################
######################################################################

# Software for simulation
## Selection on Finite Sites under Complex Demographic Events (SFSCODE)
# Or
## SLIM:
SLIM is faster (and gives more or less same results than sfs_code, except when we increase Ne – unrealistic in our model system).
# So I will use SLIM.

## info for sfs_code
# in wally: sfs_code (http://sfscode.sourceforge.net/SFS_CODE/index/index.html)
/users/sfreitas1/softwares/sfs_code/bin
--rho 0 
# Recombination can involve both crossing-over and gene conversion (which may be GC-biased). Crossing-over is easy to incorporate
# using the following template (see section 4.5 for alonger discussion involving gene conversion):
--rho (-r) 0 # for no crossing over events
# multiple simulations can be performed iteratively by changing the parameter <Niter>.
# The default initial burn-in time is 5×PN generations (where P is the ploidy,and N is the initial simulated population size,
# while subsequent burn-in periods areonly 2×PN. You can change the initial burn-in time using
--BURN (-B) <burn>
# and change the subsequent burn-in periods (for iterations>1) using
--BURN2 (-b) <burn>
# In SFSCODE, it is also possible to simulate an arbitrary number of loci (linked or unlinked) of arbitrary length using the following option.
--length (-L) <nloci> <L1> [<L2>...<Lnloci>] [R]
This option allows you to simulate<nloci>. The first locus will have length <L1>. You can stop here to set all loci to the same length. Otherwise, you have two options. You can specify each of <L2>...<Lnloci> to set the lengths of each locus, or if you have a repeating pattern (e.g.a shortlocus followed by a long one) you can specify a subset of lengths followed by the character ‘R’. Forexample, if you want to simulate 4 loci, with lengths (500bp, 1kb, 500bp, 1kb), then you could useeither of the following commands.Ex. 4.$ ./sfscode 1 1 -L 4 500 1000 500 1000$ ./sfscode 1 1 -L 4 500 1000 R






### SLIM (runs on my computer)
/home/susana/SOFTWARES/SLiM/build

initialize() {
        // set the overall mutation rate
        initializeMutationRate(1e-7);

        // m1 mutation type: neutral
        initializeMutationType("m1", 0.5, "f", 0.0);

        initializeGenomicElementType("g1", m1, 1.0);
        initializeGenomicElementType("g2", m1, 1.0);
        initializeGenomicElementType("g3", m1, 1.0);
        initializeGenomicElementType("g4", m1, 1.0);
        initializeGenomicElementType("g5", m1, 1.0);
        initializeGenomicElementType("g6", m1, 1.0);
        initializeGenomicElementType("g7", m1, 1.0);
        initializeGenomicElementType("g8", m1, 1.0);
        initializeGenomicElementType("g9", m1, 1.0);
        initializeGenomicElementType("g10", m1, 1.0);
        initializeGenomicElementType("g11", m1, 1.0);
        initializeGenomicElementType("g12", m1, 1.0);
        initializeGenomicElementType("g13", m1, 1.0);
        initializeGenomicElement(g1, 0, 1810);
        initializeGenomicElement(g2, 1811, 2983);
        initializeGenomicElement(g3, 2984, 8015);
        initializeGenomicElement(g4, 8016, 12983);
        initializeGenomicElement(g5, 12984, 15221);
        initializeGenomicElement(g6, 15222, 17505);
        initializeGenomicElement(g7, 17506, 18676);
        initializeGenomicElement(g8, 18677, 22203);
        initializeGenomicElement(g9, 22204, 22619);
        initializeGenomicElement(g10, 22620, 24837);
        initializeGenomicElement(g11, 24838, 27018);
        initializeGenomicElement(g12, 27019, 27438);
        initializeGenomicElement(g13, 27439, 29804);

        // there is no recombination acting on these genomes
        initializeRecombinationRate(0.0);
}
1 {
        sim.addSubpop("p1", 500);
        p1.setCloningRate(1.0);
} 1400000 late() { 
        g = p1.sampleIndividuals(23).genomes;
        g.outputVCF(simplifyNucleotides=T);
}



 (((((((((((( )))))))))))
 (((((((( CONTINUE HERE )))))))))
 (((((((( 10 Setembro 2019 ))))))))
 (((((((((((( )))))))))))


./slim asex.txt > asex
./slim asex-recomb-low.txt > asex-recomb-low
./slim asex-recomb-high.txt > asex-recomb-high



./slim selfing-recomb-no.txt > selfing
./slim selfing-recomb-low.txt > selfing-recomb-low
./slim selfing-recomb-high.txt > selfing-recomb-high

#

## IBS (identity-by-state) similarity matrix
# For the N individuals in a sample, to create a N x N matrix of genome-wide average IBS pairwise identities: 
plink --file mydata --cluster --matrix 

# creates the file
plink.mibs

# which contains a square, symmetric matrix of the IBS distances for all pairs of individuals.
# These values range, in theory, from 0 to 1. In practice, one would never expect to observe values near 0
# -- even completely unrelated individuals would be expected to share a very large proportion of the genome
# identical by state by chance alone (i.e. as opposed to identity by descent). A value of 1 would indicate a MZ twin pair,
# or a sample duplication. More details on pairwise relatedness can be obtained by using the --genome command.

# The default behavior of --matrix to to output similarities (proportions of alleles IBS).
# To generate a distance matrix (1-IBS) then use the command
plink --file mydata --cluster --distance-matrix
# instead. This will generate a file
plink.mdist











vcf_reader = vcf.Reader(open("Tms.alprim.vcf", 'r'))
vcf_writer = vcf.Writer(open('Tms.pyfilt2.vcf', 'w'), vcf_reader)
for record in vcf_reader:
	for call in record:
		#print(call.data.AD)
		depth=call.data.AD
		print(depth)
# only use biallelic SNPs		
		if len(depth) and sum(depth[0:])>9:
			#vcf_writer.write_record(record)
			print(record)
		else:
			continue






module load UHTS/Quality_control/qualimap/2.2.1
qualimap bamqc -nt 8 -bam Tms9_P2-trim3.filtered.bam -outdir results_folder


GenomeAnalysisTK.jar VariantsToTable \
 -R 3_Tmsb3v08.fasta \
 -V Tms.fb.vcf \
 -F CHROM -F POS -GF GT -GF DP \
 -o Tms.fb.DP.table



vcftools --remove-indv Tms19_P2^M --vcf Tms.scaf.P1.vcf --out Tms.scaf.all-P1.vcf

 




